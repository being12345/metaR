{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# python\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "\n",
    "# random\n",
    "import random\n",
    "#data analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "import sklearn\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "#d2l\n",
    "import d2l.torch as d2l\n",
    "\n",
    "# For plotting learning curve\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# auto load change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:25:53.654678600Z",
     "start_time": "2023-11-23T06:25:47.066970800Z"
    }
   },
   "id": "2499a40e3ae386ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improvement\n",
    "+ use parameter instead of hard-code for base class and task settings\n",
    "+ metaR `batchnorm1d` is canceled by me"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4052c26466f5867"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset set up\n",
    "+ NELL one: 30 base classes, 21 novel classes(3 way 5 shot 7 sessions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14fbfdefbf2f1a16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset and DataLoader\n",
    "+ 基于 base class or novel class 数量构建 train_task.\n",
    "use `next_batch` to get train_task shape: `(4, batch_size, num)`\n",
    "+ every epoch will get same relations(`self.curr_rel_idx` will ensure this)\n",
    "### construct support and query\n",
    "random choose support(相同数量 positive and negative) query(相同数量 positive and negative) according to current relation\n",
    "+ support query shape: `(batch_size, num, 2(e1_e2), embedding_shape)`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a51f0a0f1339d505"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30f4737e5b6e832a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MetaR train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc2366e93fb9b9a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### embedding entity\n",
    "get embeddings according to entity id "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38ae403f2a29760e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### relation learner\n",
    "![](imgs/img.png)\n",
    "![](imgs/img_4.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d516b8032ef8a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gradient descent in support \n",
    "![](imgs/img_1.png)\n",
    "![](imgs/img_2.png)\n",
    "![](imgs/img_3.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fedf8f1c4bc7478"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 2D or 3D input (got 4D input)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m a \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones([\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m100\u001B[39m])\n\u001B[0;32m      2\u001B[0m net \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBatchNorm1d(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda\\envs\\kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda\\envs\\kaggle\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:138\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_input_dim\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;66;03m# exponential_average_factor is set to self.momentum\u001B[39;00m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;66;03m# (when it is available) only so that it gets updated\u001B[39;00m\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmomentum \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\conda\\envs\\kaggle\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:301\u001B[0m, in \u001B[0;36mBatchNorm1d._check_input_dim\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_input_dim\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m--> 301\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    302\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected 2D or 3D input (got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124mD input)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim())\n\u001B[0;32m    303\u001B[0m         )\n",
      "\u001B[1;31mValueError\u001B[0m: expected 2D or 3D input (got 4D input)"
     ]
    }
   ],
   "source": [
    "# Test BatchNorm1d\n",
    "a = torch.ones([3, 1, 2, 100])\n",
    "inputs.contiguous().view(size[0], size[1], -1)\n",
    "net = nn.BatchNorm1d(1)\n",
    "net(a)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T13:06:56.756980Z",
     "start_time": "2023-11-22T13:06:56.294916400Z"
    }
   },
   "id": "327c964be8354155"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## eval model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda5a46198657b96"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train_tasks ... ...\n",
      "loading test_tasks ... ...\n",
      "loading dev_tasks ... ...\n",
      "loading rel2candidates ... ...\n",
      "loading e1rel_e2 ... ...\n",
      "loading ent2id ... ...\n"
     ]
    }
   ],
   "source": [
    "# TODO: simplify it into a function\n",
    "import json\n",
    "import numpy as np\n",
    "tail = ''\n",
    "data_dir = {\n",
    "    'train_tasks_in_train': './NELL/train_tasks_in_train.json',\n",
    "    'train_tasks': './NELL/continual_train_tasks.json',\n",
    "    'test_tasks': './NELL/test_tasks.json',\n",
    "    'dev_tasks': './NELL/continual_dev_tasks.json',\n",
    "\n",
    "    'rel2candidates_in_train': './NELL/rel2candidates_in_train.json',\n",
    "    'rel2candidates': './NELL/rel2candidates.json',\n",
    "\n",
    "    'e1rel_e2_in_train': './NELL/e1rel_e2_in_train.json',\n",
    "    'e1rel_e2': './NELL/e1rel_e2.json',\n",
    "\n",
    "    'ent2ids': './NELL/ent2ids',\n",
    "    'ent2vec': './NELL/ent2vec.npy',\n",
    "}\n",
    "dataset = dict()\n",
    "print(\"loading train_tasks{} ... ...\".format(tail))\n",
    "dataset['train_tasks'] = json.load(open(data_dir['train_tasks' + tail]))\n",
    "print(\"loading test_tasks ... ...\")\n",
    "dataset['test_tasks'] = json.load(open(data_dir['test_tasks']))\n",
    "print(\"loading dev_tasks ... ...\")\n",
    "dataset['dev_tasks'] = json.load(open(data_dir['dev_tasks']))\n",
    "print(\"loading rel2candidates{} ... ...\".format(tail))\n",
    "dataset['rel2candidates'] = json.load(open(data_dir['rel2candidates' + tail]))\n",
    "print(\"loading e1rel_e2{} ... ...\".format(tail))\n",
    "dataset['e1rel_e2'] = json.load(open(data_dir['e1rel_e2' + tail]))\n",
    "print(\"loading ent2id ... ...\")\n",
    "dataset['ent2id'] = json.load(open(data_dir['ent2ids']))\n",
    "dataset['ent2emb'] = np.load(data_dir['ent2vec'])\n",
    "from data_loader import DataLoader\n",
    "params = {'few': 1, 'num_query': 3, 'batch_size': 16, 'base_classes_few': 10, 'base_classes_num_query': 30, 'base_classes_relation': 30}\n",
    "train_data_loader = DataLoader(dataset, params, step='train')\n",
    "dev_data_loader = DataLoader(dataset, params, step='dev')\n",
    "test_data_loader = DataLoader(dataset, params, step='test')\n",
    "data_loaders = [train_data_loader, dev_data_loader, test_data_loader]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:28:38.679682400Z",
     "start_time": "2023-11-23T09:28:37.590844100Z"
    }
   },
   "id": "2916022e7b128402"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for k,v in dataset['dev_tasks'].items():\n",
    "    print(len(v))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:29:28.100029200Z",
     "start_time": "2023-11-23T09:29:27.318233600Z"
    }
   },
   "id": "de94857cb7fd006b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# 3 support 3 query\n",
    "dev_tasks = {}\n",
    "train_tasks = {}\n",
    "for k, v in dataset['train_tasks'].items():\n",
    "    dev_tasks[k] = []\n",
    "    train_tasks[k] = []\n",
    "    for i in range(len(v)):\n",
    "        if i < 12:\n",
    "            dev_tasks[k].append(v.pop())\n",
    "        else:\n",
    "            train_tasks[k].append(v.pop())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T07:02:05.705543300Z",
     "start_time": "2023-11-23T07:02:04.479056700Z"
    }
   },
   "id": "b7144d95d74c0227"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for k, v in dev_tasks.items():\n",
    "    print(len(v))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b6e596ea06f586a"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Convert and write JSON object to file\n",
    "with open(\"NELL/continual_train_tasks\", \"w\") as outfile:\n",
    "    json.dump(train_tasks, outfile)\n",
    "with open(\"NELL/continual_dev_tasks\", \"w\") as outfile:\n",
    "    json.dump(dev, outfile)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af819f35438f120b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "41bdf08eb7dfd848"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
