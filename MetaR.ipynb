{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# python\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "\n",
    "# random\n",
    "import random\n",
    "#data analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "import sklearn\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "#d2l\n",
    "import d2l.torch as d2l\n",
    "\n",
    "# For plotting learning curve\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# auto load change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:20:47.881274100Z",
     "start_time": "2023-12-01T09:20:38.570015800Z"
    }
   },
   "id": "2499a40e3ae386ff"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERelationMetaLearner(\n",
      "  (rel_fc1): Sequential(\n",
      "    (fc): SubnetLinear(in_features=200, out_features=500, bias=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (rel_fc2): Sequential(\n",
      "    (fc): SubnetLinear(in_features=500, out_features=200, bias=False)\n",
      "    (relu): LeakyReLU(negative_slope=0.01)\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (rel_fc3): Sequential(\n",
      "    (fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      ")\n",
      "rel_fc1\n",
      "Sequential(\n",
      "  (fc): SubnetLinear(in_features=200, out_features=500, bias=False)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "rel_fc1.fc\n",
      "SubnetLinear(in_features=200, out_features=500, bias=False)\n",
      "rel_fc1.relu\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "rel_fc1.drop\n",
      "Dropout(p=0.5, inplace=False)\n",
      "rel_fc2\n",
      "Sequential(\n",
      "  (fc): SubnetLinear(in_features=500, out_features=200, bias=False)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "rel_fc2.fc\n",
      "SubnetLinear(in_features=500, out_features=200, bias=False)\n",
      "rel_fc2.relu\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "rel_fc2.drop\n",
      "Dropout(p=0.5, inplace=False)\n",
      "rel_fc3\n",
      "Sequential(\n",
      "  (fc): Linear(in_features=200, out_features=100, bias=True)\n",
      ")\n",
      "rel_fc3.fc\n",
      "Linear(in_features=200, out_features=100, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from network.param_emb_models import PERelationMetaLearner\n",
    "\n",
    "model = PERelationMetaLearner(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:27:54.504906100Z",
     "start_time": "2023-12-01T09:27:53.748646300Z"
    }
   },
   "id": "426dd8e824d1a57a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improvement\n",
    "+ use parameter instead of hard-code for **base class and task** settings\n",
    "+ metaR `batchnorm1d` is canceled by me"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4052c26466f5867"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset set up\n",
    "+ NELL one: 30 base classes, 21 novel classes(3 way 5 shot 7 sessions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14fbfdefbf2f1a16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset and DataLoader\n",
    "+ 基于 base class or novel class 数量构建 train_task.\n",
    "use `next_batch` to get train_task shape: `(4, batch_size, num)`\n",
    "+ every epoch will get same relations(`self.curr_rel_idx` will ensure this)\n",
    "### construct support and query\n",
    "random choose support(相同数量 positive and negative) query(相同数量 positive and negative) according to current relation\n",
    "+ support query shape: `(batch_size, num, 2(e1_e2), embedding_shape)`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a51f0a0f1339d505"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30f4737e5b6e832a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MetaR train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc2366e93fb9b9a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### embedding entity\n",
    "get embeddings according to entity id "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38ae403f2a29760e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### relation learner\n",
    "![](imgs/img.png)\n",
    "![](imgs/img_4.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d516b8032ef8a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gradient descent in support \n",
    "![](imgs/img_1.png)\n",
    "![](imgs/img_2.png)\n",
    "![](imgs/img_3.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fedf8f1c4bc7478"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## eval model\n",
    "+ loop all triples in eval \n",
    "+ get one query and support per time\n",
    "+ predict rank\n",
    "\n",
    "+ If relation is same?\n",
    "\n",
    "+ self.curr_tri_idx filter by relation(cache past relations)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda5a46198657b96"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train_tasks ... ...\n",
      "loading test_tasks ... ...\n",
      "loading dev_tasks ... ...\n",
      "loading rel2candidates ... ...\n",
      "loading e1rel_e2 ... ...\n",
      "loading ent2id ... ...\n"
     ]
    }
   ],
   "source": [
    "# TODO: simplify it into a function\n",
    "import json\n",
    "import numpy as np\n",
    "tail = ''\n",
    "data_dir = {\n",
    "    'train_tasks_in_train': './NELL/train_tasks_in_train.json',\n",
    "    'train_tasks': './NELL/continual_train_tasks.json',\n",
    "    'test_tasks': './NELL/test_tasks.json',\n",
    "    'dev_tasks': './NELL/continual_dev_tasks.json',\n",
    "\n",
    "    'rel2candidates_in_train': './NELL/rel2candidates_in_train.json',\n",
    "    'rel2candidates': './NELL/rel2candidates.json',\n",
    "\n",
    "    'e1rel_e2_in_train': './NELL/e1rel_e2_in_train.json',\n",
    "    'e1rel_e2': './NELL/e1rel_e2.json',\n",
    "\n",
    "    'ent2ids': './NELL/ent2ids',\n",
    "    'ent2vec': './NELL/ent2vec.npy',\n",
    "}\n",
    "dataset = dict()\n",
    "print(\"loading train_tasks{} ... ...\".format(tail))\n",
    "dataset['train_tasks'] = json.load(open(data_dir['train_tasks' + tail]))\n",
    "print(\"loading test_tasks ... ...\")\n",
    "dataset['test_tasks'] = json.load(open(data_dir['test_tasks']))\n",
    "print(\"loading dev_tasks ... ...\")\n",
    "dataset['dev_tasks'] = json.load(open(data_dir['dev_tasks']))\n",
    "print(\"loading rel2candidates{} ... ...\".format(tail))\n",
    "dataset['rel2candidates'] = json.load(open(data_dir['rel2candidates' + tail]))\n",
    "print(\"loading e1rel_e2{} ... ...\".format(tail))\n",
    "dataset['e1rel_e2'] = json.load(open(data_dir['e1rel_e2' + tail]))\n",
    "print(\"loading ent2id ... ...\")\n",
    "dataset['ent2id'] = json.load(open(data_dir['ent2ids']))\n",
    "dataset['ent2emb'] = np.load(data_dir['ent2vec'])\n",
    "from data_loader import DataLoader\n",
    "params = {'few': 1, 'num_query': 3, 'batch_size': 16, 'base_classes_few': 10, 'base_classes_num_query': 30, 'base_classes_relation': 30}\n",
    "train_data_loader = DataLoader(dataset, params, step='train')\n",
    "dev_data_loader = DataLoader(dataset, params, step='dev')\n",
    "test_data_loader = DataLoader(dataset, params, step='test')\n",
    "data_loaders = [train_data_loader, dev_data_loader, test_data_loader]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:27:20.842606500Z",
     "start_time": "2023-11-23T12:27:20.523752600Z"
    }
   },
   "id": "2916022e7b128402"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "eval_triples = []\n",
    "all_rels = sorted(list(dataset['dev_tasks'].keys()))\n",
    "for rel in all_rels:\n",
    "    eval_triples.extend(dataset['dev_tasks'][rel][3:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:29:26.522784100Z",
     "start_time": "2023-11-23T12:29:26.501232300Z"
    }
   },
   "id": "30de08d2b702a5d5"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# eval_triples = []\n",
    "eval_triples.extend(dataset['dev_tasks'][all_rels[0]][:3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:33:03.409418Z",
     "start_time": "2023-11-23T12:33:03.385421Z"
    }
   },
   "id": "4e52341798a02474"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[['concept:academicfield:management_program',\n  'concept:academicfieldsuchasacademicfield',\n  'concept:academicfield:business'],\n ['concept:academicfield:social_work',\n  'concept:academicfieldsuchasacademicfield',\n  'concept:academicfield:business'],\n ['concept:academicfield:biology',\n  'concept:academicfieldsuchasacademicfield',\n  'concept:politicsissue:environment'],\n ['concept:academicfield:management_program',\n  'concept:academicfieldsuchasacademicfield',\n  'concept:academicfield:business'],\n ['concept:academicfield:social_work',\n  'concept:academicfieldsuchasacademicfield',\n  'concept:academicfield:business'],\n ['concept:academicfield:biology',\n  'concept:academicfieldsuchasacademicfield',\n  'concept:politicsissue:environment']]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_triples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:33:03.792886600Z",
     "start_time": "2023-11-23T12:33:03.780890500Z"
    }
   },
   "id": "2b921407f7f8047d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "92"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['dev_tasks'][all_rels[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T12:31:42.102981600Z",
     "start_time": "2023-11-23T12:31:42.081977500Z"
    }
   },
   "id": "e6fbc1fade98b0b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test relation in eval\n",
    "# repeat relation is same"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ac5be14222ea4ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
